## Setting model

1. Download weights for each model;
2. Change to your path in the corresponding to the code.


### OpenFlamingo

We refer to the official repo [OpenFlamingo](https://github.com/mlfoundations/open_flamingo).

Download weights:  

[OpenFlamingo](https://huggingface.co/openflamingo/OpenFlamingo-9B-deprecated)


### Multimodal-GPT

We refer to the official repo [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT).

Download weights:  

[llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf),
[OpenFlamingo-9B](https://huggingface.co/openflamingo/OpenFlamingo-9B-deprecated),
[mmgpt-lora-v0-release.pt](https://github.com/open-mmlab/Multimodal-GPT#:~:text=LoRA%20Weight%20from-,here,-.).



### LaVIN 

We refer to the official repo [LaVIN](https://github.com/luogen1996/LaVIN).

For **LaVIN-7B**, download weights: 

[LLaMA-7B](https://huggingface.co/nyanko7/LLaMA-7B/tree/main),
[sqa-llama-7b-lite.pth](https://drive.google.com/file/d/1oVtoTgt-d9EqmrVic27oZUreN9dLClMo/view).

For **LaVIN-13B**, download weights: 

[LLaMA-13B](https://huggingface.co/TheBloke/llama-13b),
[sqa-llama-13b-lite.pth](https://drive.google.com/file/d/1PyVsap3FnmgXOGXFXjYsAtR75cFypaHw/view).


### Lynx-llm

We refer to the official repo [Lynx-llm](https://github.com/bytedance/lynx-llm/tree/main).

Download weights:  

[EVA01_g_psz14.pt](https://github.com/bytedance/lynx-llm/tree/main#:~:text=eva_vit_1b%20on%20official-,website,-and%20put%20it),
[vicuna-7b](https://huggingface.co/lmsys/vicuna-7b-v1.1),
[finetune_lynx.pt](https://github.com/bytedance/lynx-llm/tree/main#:~:text=pretrain_lynx.pt%20or-,finetune_lynx.pt,-and%20put%20it).


### Flan-T5-XXL, BLIP2, InstructBLIP, Fromage can auto-download.

### Other models will be updated soon.

